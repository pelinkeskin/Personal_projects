### AI_flappybird_player_Deep_Reinforcement_Learning
I completed this project as part of an assignment in one of my modules during my Masters. The project involved training an AI agent who plays the Flappy Bird game using deep reinforcement learning. In this project, I used Stable Baselines 3 to train a neural network to control the bird in the [Flappy Bird environment](https://github.com/markub3327/flappy-bird-gymnasium). I used an actor-critic algorithm with (PPO) proximal policy optimization to create the network to train a vector agent and an Image stack agent to play the flappy bird game. To train the vector agent, I used the FlappyBird-v0 environment and MlpPolicy, the other hyperparameters of the network, for training the PPO agent provided to us in the assignment. To train the image stack agent, I used FlappyBird-rgb-v0 environment but resized images to 64*128, changed to grey-scale and stacked four frames together, and I used CnnPolicy, the other hyperparameters of the network for training the PPO agent provided to us in the assignment. The number of trainable weights and biases in the vector agent model was 10,179, and in the image stack agent model was 4,955,619. Therefore, training took a very long time, and even after 500.000-time step models were undertrained, I didn't continue training due to computational limitations. The best performance evaluated for 30 episodes after training for  500,000 timesteps was 11.83 mean award of image stack agent. 
