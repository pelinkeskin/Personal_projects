### Kaggle Home Credit - Credit Risk Model Stability Competition
This directory encompasses my entry for the [Kaggle Home Credit - Credit Risk Model Stability competition](https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability). The goal of this competition was to predict which clients are more likely to default on their loans, with a focus on solutions that remain stable over time. This notebook is my submission to the HomeCredit Credit Risk Model Stability competition. Although I initially intended to use all available data, concerns about metrics and potential exploits led me to limit my scope, using only data from depths 0-1 and performing evaluations with train-validation-test splits without a cross-validation scheme. The main challenge was memory management, so I built a pipeline that utilized Dask for scalability when applicable. This pipeline incorporated dtype optimization, data cleaning, feature engineering for time features, TF-IDF encoding for categorical features, data normalization, and feature selection using recursive feature elimination with a ridge classifier. I also used a semi-tuned XGBoost model for feature selection based on optimized feature importance thresholds.

Preliminary evaluations with untuned XGBoost models identified the DART booster as the most promising, leading me to optimize its hyperparameters using Optuna. Due to time constraints, optimization trials were limited to 60 experiments. Fortunately, the decision boundaries of the top three best models were diverse enough to build a voting ensemble. Averaging the results of these top three models resulted in a more stable model. This approach ensured that my final submission balanced performance and stability, aligning with the competition's objectives.

I am pleased to share that this notebook is publicly accessible on [Kaggle](https://www.kaggle.com/code/pelinkeskin/homecredit-dask-xgboost-optuna) and welcomes comments and feedback from the community.
